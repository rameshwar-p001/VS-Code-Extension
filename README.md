# Chat Assistant Extension

This is a VS Code sidebar extension that allows you to chat with a locally running LLM (DeepSeek Coder) using Ollama. It supports prompt sending, response display, and a nice chat-style interface.

## Features
- Send prompts to DeepSeek Coder via localhost
- Receive and display responses in a webview
- Chat-style interface
# 💬 VS Code Chat Assistant (Local LLM Integration)

This is a powerful VS Code extension that brings an AI chat assistant directly into your sidebar — **no internet, no API key required**. It connects to a locally running Large Language Model (LLM) like **DeepSeek Coder via Ollama**, and helps you with:

- 💻 Code suggestions  
- ❓ Error explanations  
- 📘 Learning programming concepts  
- 🔁 Chat-style history with context

---

## ⚙️ Features

- 🧠 Connects to local LLM (DeepSeek Coder)
- 🪄 Clean, minimal, and modern sidebar UI
- 💬 Chat history in a scrollable panel
- 🔁 Loop support for continuous interaction
- 📤 Coming Soon: Save, Export, and Clear buttons!

---

## 🚀 Setup Instructions

1. Install [Ollama](https://ollama.com/) and run:
   ```bash
   ollama run deepseek-coder
Clone this repo and open it in VS Code.

Run the extension:

Press F5 to open a new Extension Development Host window.

Open the Command Palette (Ctrl+Shift+P) → Chat Assistant: Start.

📁 Tech Stack
🧩 JavaScript (VS Code Extension API)

🎨 HTML + CSS (for custom UI)

🔗 HTTP (connects to localhost:11434 for model inference)

🧠 DeepSeek Coder via Ollama

🙌 Credits
Made with ❤️ by Patil Rameshwar D
📍 Pimpri Chinchwad University
Special thanks to Mrs. Ruchira K Karanjikar for constant guidance.

📌 Screenshot

📌 Note
This is an experimental personal project integrating LLMs locally. Feel free to fork and improve it!
